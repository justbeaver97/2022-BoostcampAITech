{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML: eXtensible Markup Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/6d/6463d49a933f547439d6b5b98b46af8742cc03ae83543e4d7688c2420f8b/pip-21.3.1-py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-21.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting BeautifulSoup4\n",
      "  Using cached beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.6.4-cp38-cp38-macosx_10_14_x86_64.whl (4.5 MB)\n",
      "     |████████████████████████████████| 4.5 MB 2.2 MB/s             \n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, lxml, BeautifulSoup4\n",
      "Successfully installed BeautifulSoup4-4.10.0 lxml-4.6.4 soupsieve-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install BeautifulSoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<author>Carson</author>\n",
      "Carson\n",
      "<author>Sungchul</author>\n",
      "Sungchul\n"
     ]
    }
   ],
   "source": [
    "with open(\"input_file/books.xml\",\"r\",encoding=\"utf8\") as books_file:\n",
    "    books_xml = books_file.read()\n",
    "\n",
    "soup = BeautifulSoup(books_xml, \"lxml\")\n",
    "\n",
    "for book_info in soup.find_all(\"author\"):\n",
    "    print(book_info)\n",
    "    print(book_info.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<invention-title id=\"d2e43\">Adjustable shoulder device for hard upper torso suit</invention-title>\n"
     ]
    }
   ],
   "source": [
    "with open(\"input_file/US08621662-20140107.xml\",\"r\",encoding=\"utf8\") as patent_xml:\n",
    "    xml = patent_xml.read()\n",
    "\n",
    "soup = BeautifulSoup(xml, \"lxml\")\n",
    "\n",
    "invention_title_tag = soup.find(\"invention-title\")\n",
    "print(invention_title_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08621662 B2 20140107\n"
     ]
    }
   ],
   "source": [
    "publication_reference_tag = soup.find(\"publication-reference\") \n",
    "p_document_id_tag = publication_reference_tag.find(\"document-id\") \n",
    "p_country = p_document_id_tag.find(\"country\").get_text() \n",
    "p_doc_number = p_document_id_tag.find(\"doc-number\").get_text() \n",
    "p_kind = p_document_id_tag.find(\"kind\").get_text()\n",
    "p_date = p_document_id_tag.find(\"date\").get_text()\n",
    "\n",
    "print(p_doc_number, p_kind, p_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US 08621662 20140107\n"
     ]
    }
   ],
   "source": [
    "application_reference_tag = soup.find(\"application-reference\") \n",
    "a_document_id_tag = publication_reference_tag.find(\"document-id\") \n",
    "a_country = p_document_id_tag.find(\"country\").get_text() \n",
    "a_doc_number = p_document_id_tag.find(\"doc-number\").get_text() \n",
    "a_date = p_document_id_tag.find(\"date\").get_text()\n",
    "\n",
    "print(a_country, a_doc_number, a_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 실습 파일은 어떻게 해야할까 고민..\n",
    "\n",
    "# import os\n",
    "# import urllib\n",
    "# import csv\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# def writeToCSV(patent_infos):\n",
    "#     with open(\"output/patent_csv.csv\",\"w\") as csv_file:\n",
    "#         cw = csv.writer(csv_file, delimiter=\",\", quotechar=\"'\")\n",
    "#         for patent_info in patent_infos:\n",
    "#             cw.writerow(patent_info)\n",
    "            \n",
    "# patent_dir = \"input/patent\"\n",
    "# file_list = os.listdir(patent_dir)\n",
    "\n",
    "# patent_infos = [] \n",
    "# patent_info = []\n",
    "\n",
    "# for patent_file_name in file_list:\n",
    "#     full_path = patent_dir + \"/\" + patent_file_name"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

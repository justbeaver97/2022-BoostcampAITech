{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595cbcb0-19c2-4e5a-bb65-3cd7adec3c9e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1123d2d2-ed5b-4971-8f51-ede968ceef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# 데이터 분석 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 시각화 라이브러리\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43cb17ec-8e7d-411b-a24e-c1a2d80092fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import timm\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34276d73-aecc-4007-b4e0-fc21d6446267",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"../input/data\"\n",
    "TRAIN_PATH = os.path.join(IMAGE_PATH, 'train')\n",
    "TEST_PATH = os.path.join(IMAGE_PATH, 'eval')\n",
    "TRAIN_IMAGE_PATH = os.path.join(TRAIN_PATH, 'images/')\n",
    "TEST_IMAGE_PATH = os.path.join(TEST_PATH, 'images/')\n",
    "TRAIN_CSV_PATH = os.path.join(TRAIN_PATH, 'train.csv')\n",
    "TEST_CSV_PATH = os.path.join(TEST_PATH, 'info.csv')\n",
    "\n",
    "DATASET_PATH = os.path.join(TRAIN_PATH, 'dataset')\n",
    "DATASET_IMAGE_PATH = os.path.join(DATASET_PATH, 'train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4cab9-3af9-486e-82ef-4728a5be5dd2",
   "metadata": {},
   "source": [
    "# Defining the save_noisy_image Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8535e6f1-2a03-442b-91ad-864c22200779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_noisy_image(img, name):\n",
    "    img = img.view(img.size(0), 3, 224, 224)\n",
    "    save_image(img, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcef4b6-2424-4600-860d-d58a3292ec8b",
   "metadata": {},
   "source": [
    "# HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70acdde2-2349-4c88-bcc6-904446b7943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa7242e-4747-49c5-8afe-5078fedc4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([image_width,image_height]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([      \n",
    "        transforms.Resize([image_width,image_height]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "batch_size_for_augmentation = 1\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d1a83-3d94-49bb-bb08-f854dd5c6b38",
   "metadata": {},
   "source": [
    "# Defining Nosie Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48226769-438a-4cc2-8d2a-e46a3aca7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise():\n",
    "    count = 1\n",
    "    for image, label in dataloaders['train']:\n",
    "        trainPath = DATASET_IMAGE_PATH\n",
    "        noisePath = str(int(label))\n",
    "        Path = os.path.join(trainPath, noisePath)\n",
    "#         print(Path)\n",
    "\n",
    "#         name = \"1.png\"\n",
    "        name = '{}{}{}'.format(\"gaussian\",count, \".jpg\")\n",
    "        finalPath = os.path.join(Path,name)\n",
    "#         print(finalPath)\n",
    "\n",
    "        gauss_img = torch.tensor(random_noise(image, mode='gaussian', mean=0, var=0.05, clip=True))\n",
    "#         # save_noisy_image(gauss_img, \"noise_image/art_gaussian.png\")\n",
    "        save_noisy_image(gauss_img, finalPath)\n",
    "        \n",
    "        count += 1\n",
    "#         # print(\"count\",count,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64bc213-1f45-4a61-ac89-aaf76d5d1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_paper_noise():\n",
    "    count = 1\n",
    "    for image, label in dataloaders['train']:   \n",
    "        trainPath = DATASET_IMAGE_PATH\n",
    "        noisePath = str(int(label))\n",
    "        Path = os.path.join(trainPath, noisePath)\n",
    "        # print(Path)\n",
    "\n",
    "        # name = \"1.png\"\n",
    "        name = '{}{}{}'.format(\"saltandpeppper\",count, \".jpg\")\n",
    "        finalPath = os.path.join(Path,name)\n",
    "        # print(finalPath)\n",
    "\n",
    "        salt_img = torch.tensor(random_noise(image, mode='salt', amount=0.05))\n",
    "        # save_noisy_image(gauss_img, \"noise_image/art_gaussian.png\")\n",
    "        save_noisy_image(salt_img, finalPath)\n",
    "        \n",
    "        count += 1\n",
    "        # print(\"count\",count,end=' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a7e869-7a9b-47fa-bfa9-31d9bb2bf259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speckle_noise():\n",
    "    count = 1\n",
    "    for image, label in dataloaders['train']:\n",
    "        trainPath = DATASET_IMAGE_PATH\n",
    "        noisePath = str(int(label))\n",
    "        Path = os.path.join(trainPath, noisePath)\n",
    "        # print(Path)\n",
    "\n",
    "        # name = \"1.png\"\n",
    "        name = '{}{}{}'.format(\"sparkler\",count, \".jpg\")\n",
    "        finalPath = os.path.join(Path,name)\n",
    "        # print(finalPath)\n",
    "\n",
    "        speckle_img = torch.tensor(random_noise(image, mode='speckle', mean=0, var=0.05, clip=True))\n",
    "        # save_noisy_image(gauss_img, \"noise_image/art_gaussian.png\")\n",
    "        save_noisy_image(speckle_img, finalPath)\n",
    "        \n",
    "        count += 1\n",
    "        # print(\"count\",count,end=' ') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5970f9e-650c-4589-91d1-e9f52d1237d4",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38498c4-60ec-400d-9243-776ddaf805cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train/dataset'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                        data_transforms[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92dfeccc-9092-4a4c-ad3b-9eb3f3404798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72ac56-7426-40af-b897-465ae2a92a6d",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163eb17b-a79a-43f9-9ec6-e52cf591682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(\n",
    "    image_datasets[x], \n",
    "    batch_size=batch_size_for_augmentation, \n",
    "    shuffle=True, num_workers = num_workers\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in ['train','val']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e65a749c-d725-43be-b5bb-43820d735278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f1998e00c40>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7f18b7b1d040>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af96e1-6c34-494e-91b1-51f907fecee6",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2209aada-bf15-4a79-a780-0acc428cd39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778e990e-c02f-48fc-8202-c222dd800861",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_paper_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89407091-b412-435c-aaba-d91a79ea2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "speckle_noise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
